name: Enhanced Manga Scraper

on:
  schedule:
    # Run every 6 hours
    - cron: '0 */6 * * *'
  workflow_dispatch:
    inputs:
      limit:
        description: 'Number of manga to scrape (0 for all)'
        required: false
        default: '0'

jobs:
  scrape-and-update:
    runs-on: ubuntu-latest
    
    permissions:
      contents: write
      
    steps:
    - name: Checkout repository
      uses: actions/checkout@v4
      
    - name: Set up Python
      uses: actions/setup-python@v5
      with:
        python-version: '3.10'
        cache: 'pip'
        
    - name: Install dependencies
      run: |
        python -m pip install --upgrade pip
        if [ -f requirements.txt ]; then pip install -r requirements.txt; fi
        
    - name: Run Scraper
      run: |
        # Use curl to verify connectivity first (per user preference for curl tools)
        curl -I https://pretty-frank.com/
        
        # Run the Python scraper
        # Pass the limit argument if manually triggered
        LIMIT="${{ inputs.limit }}"
        if [ "$LIMIT" == "" ] || [ "$LIMIT" == "0" ]; then
          python enhanced_scraper.py
        else
          python enhanced_scraper.py $LIMIT
        fi
      
    - name: Check for changes
      id: verify_diff
      run: |
        git diff --quiet . || echo "changed=true" >> $GITHUB_OUTPUT
        
    - name: Commit and Push changes
      if: steps.verify_diff.outputs.changed == 'true'
      run: |
        git config --global user.name 'GitHub Action Scraper'
        git config --global user.email 'action@github.com'
        git add manga_*.json
        git commit -m "Auto-update manga data [skip ci]"
        git push
